import os
import re
import time
import json
import base64
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import WebDriverException
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.keys import Keys
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import pytz
from dotenv import load_dotenv

from services.email.universal_email_sender import UniversalEmailSender

# Load environment variables
load_dotenv()

# Import state mapping from helpers
from utils.vms_helpers import STATE_MAPPING, CREDENTIAL_SETS

class RequisitionProcessor:
    def __init__(self):
        self.driver = None
        self.output_dir = "vms_outputs"
        self.updated_docs_dir = "vms_documents"
        self.documents_dir = "Documents"
        
    def initialize_driver(self):
        """Initialize and return a Chrome WebDriver with optimal settings"""
        options = webdriver.ChromeOptions()
        options.add_argument("--start-maximized")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
        
        service = Service("chromedriver\\chromedriver.exe")
        driver = webdriver.Chrome(service=service, options=options)
        return driver
    
    def login_to_vectorvms(self, driver, url, credentials, max_retries=3):
        """Logs into Vector VMS system with enhanced reliability"""
        print(f"  Trying org_key: {credentials['org_key']}")
        driver.get(url)
        time.sleep(5)  # Initial wait for page load
        
        for attempt in range(max_retries):
            try:
                # Wait for login page to be fully interactive
                WebDriverWait(driver, 20).until(
                    EC.presence_of_element_located((By.TAG_NAME, 'body')))
                
                # Explicitly wait for and locate login fields
                username_field = WebDriverWait(driver, 15).until(
                    EC.presence_of_element_located((By.XPATH,
                        "//input[@type='text' or contains(@id, 'username') or contains(@name, 'username') or contains(@placeholder, 'Username')]")))
                password_field = WebDriverWait(driver, 15).until(
                    EC.presence_of_element_located((By.XPATH,
                        "//input[@type='password' or contains(@id, 'password') or contains(@name, 'password')]")))
                org_key_field = WebDriverWait(driver, 15).until(
                    EC.presence_of_element_located((By.XPATH,
                        "//input[contains(@id, 'org') or contains(@name, 'org') or contains(@placeholder, 'Organization Key')]")))

                # Fill credentials - USING EXACT VALUES FROM CREDENTIAL_SETS
                username_field.clear()
                username_field.send_keys(credentials['username'])  # 'support'
                password_field.clear()
                password_field.send_keys(credentials['password'])  # 'db3admin'
                org_key_field.clear()
                org_key_field.send_keys(credentials['org_key'])    # org_key from list

                # Click login button with improved specificity
                login_button = WebDriverWait(driver, 15).until(
                    EC.element_to_be_clickable((By.XPATH,
                        "//button[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'login') or contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'sign in')] | " +
                        "//input[@type='submit' and contains(translate(@value, 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'login')]")))
                login_button.click()
                
                # Wait for successful login or requisition page
                WebDriverWait(driver, 40).until(
                    lambda d: "reqid" in d.current_url.lower() or "dashboard" in d.current_url.lower(),
                    message="Failed to reach requisition or dashboard page")
                
                print(f"  ‚úì Login successful with org_key: {credentials['org_key']}!")
                return True

            except Exception as e:
                print(f"  Login attempt {attempt + 1}/{max_retries} failed: {str(e)}")
                if attempt < max_retries - 1:
                    print("  Retrying in 5 seconds...")
                    time.sleep(5)
                    driver.get(url)  # Reload page for retry
                else:
                    print(f"  ‚úó All login attempts failed with org_key: {credentials['org_key']}")
                    return False
    
    def logout_from_vectorvms(self, driver):
        """Logs out from Vector VMS system"""
        print("  Logging out from Vector VMS...")
        try:
            # Try to find and click logout button
            logout_button = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.XPATH, 
                    "//a[contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'logout') or " +
                    "contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ', 'abcdefghijklmnopqrstuvwxyz'), 'sign out')]")))
            logout_button.click()
            
            # Wait for logout to complete (redirect to login page)
            WebDriverWait(driver, 15).until(
                lambda d: "login" in d.current_url.lower() or "signin" in d.current_url.lower())
            
            print("  ‚úì Logout successful!")
            return True
        except Exception as e:
            print(f"  Logout failed: {str(e)}")
            # If logout fails, try to clear cookies and refresh
            try:
                driver.delete_all_cookies()
                driver.refresh()
                print("  Cleared cookies as fallback logout method")
                return True
            except:
                print("  Could not perform clean logout")
            return False
    
    def extract_complete_page_content(self, driver):
        """Extracts all visible content from the page with dynamic key-value pairs, including both short and complete descriptions"""
        
        try:
            # Wait for the main content to load
            WebDriverWait(driver, 30).until(
                EC.presence_of_element_located((By.TAG_NAME, 'body')))

            # Scroll through the entire page to load all content
            last_height = driver.execute_script("return document.body.scrollHeight")
            while True:
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                new_height = driver.execute_script("return document.body.scrollHeight")
                if new_height == last_height:
                    break
                last_height = new_height

            # Switch to main iframe if present (save the element for later if needed)
            main_iframe = None
            try:
                main_iframe = driver.find_element(By.TAG_NAME, "iframe")
                driver.switch_to.frame(main_iframe)
                print("  Switched to main iframe context")
            except:
                print("  No main iframe detected")

            # Get the page source and parse with BeautifulSoup
            page_html = driver.page_source
            soup = BeautifulSoup(page_html, 'html.parser')
            content = []
            seen_keys = set()

            # Handle section headers
            for header in soup.find_all('h2'):
                header_text = header.find('span', class_='x-panel-header-text')
                if header_text and header_text.text.strip() not in seen_keys:
                    content.append(header_text.text.strip())
                    seen_keys.add(header_text.text.strip())

            # Extract key-value pairs dynamically
            for label in soup.find_all(['label', 'span'], string=True):
                key = label.get_text(strip=True).rstrip(':')
                if key and key not in seen_keys and not any(kw in key for kw in ['label', 'header']):
                    seen_keys.add(key)
                    # Find the next value element
                    next_elem = label.find_next(['input', 'textarea', 'span', 'div'],
                                              class_=lambda c: c and ('x-label-value' in c or 'vms-viewmode-view-set' in c or 'x-form-display-field' in c))
                    if next_elem:
                        try:
                            element = driver.find_element(By.ID, next_elem.get('id'))
                            if element.tag_name == 'span':
                                value = element.text.strip()
                            elif element.tag_name in ['input', 'textarea']:
                                value = driver.execute_script("return arguments[0].value", element) or element.text.strip()
                            elif element.tag_name == 'div' and 'x-form-display-field' in element.get_attribute('class'):
                                value = element.text.strip()
                            else:
                                value = next_elem.get_text(strip=True)
                            if value and len(value) > 0:
                                content.append(f"{key}: {value}")
                            else:
                                content.append(f"{key}:")
                        except:
                            content.append(f"{key}:")
                    else:
                        content.append(f"{key}:")

            # Extract Short Description
            short_desc = ""
            try:
                # Try to find the short description section
                short_desc_div = soup.find('div', id='ContentPH_ctl209')
                if short_desc_div:
                    # Try to get content from iframe
                    iframe = short_desc_div.find('iframe')
                    if iframe:
                        driver.switch_to.frame(iframe.get('name'))
                        iframe_html = driver.page_source
                        iframe_soup = BeautifulSoup(iframe_html, 'html.parser')
                        short_desc = iframe_soup.body.get_text('\n', strip=True)
                        driver.switch_to.parent_frame()  # Switch back to parent context (main iframe)
                    else:
                        # Fallback to hidden textarea
                        hidden_textarea = short_desc_div.find('textarea', id='ContentPH_description_short_html')
                        if hidden_textarea and hidden_textarea.text.strip():
                            short_desc = hidden_textarea.text.strip()
                        else:
                            # Final fallback to display field
                            display_field = short_desc_div.find('div', id='ContentPH_lblShortDescription')
                            if display_field and display_field.text.strip():
                                short_desc = display_field.text.strip()
            except Exception as e:
                print(f"  Short description extraction error: {str(e)}")
                try:
                    driver.switch_to.parent_frame()  # Use parent_frame in except too
                except:
                    pass

            # Add short description if found
            if short_desc and short_desc.strip():
                content.append("\nSHORT DESCRIPTION:")
                content.append(short_desc.strip())

            # Extract Complete Description
            complete_desc = ""
            try:
                # Try to find the complete description section
                complete_desc_div = soup.find('div', id='ContentPH_ctl214')
                if complete_desc_div:
                    # Try to get content from iframe
                    iframe = complete_desc_div.find('iframe')
                    if iframe:
                        driver.switch_to.frame(iframe.get('name'))
                        iframe_html = driver.page_source
                        iframe_soup = BeautifulSoup(iframe_html, 'html.parser')
                        complete_desc = iframe_soup.body.get_text('\n', strip=True)
                        driver.switch_to.parent_frame()  # Switch back to parent context (main iframe)
                    else:
                        # Fallback to hidden textarea
                        hidden_textarea = complete_desc_div.find('textarea', id='ContentPH_description_html')
                        if hidden_textarea and hidden_textarea.text.strip():
                            complete_desc = hidden_textarea.text.strip()
                        else:
                            # Final fallback to display field
                            display_field = complete_desc_div.find('div', id='ContentPH_lblDescription')
                            if display_field and display_field.text.strip():
                                complete_desc = display_field.text.strip()
                # Additional fallback: search for complete description in other divs or text
                if not complete_desc:
                    for div in soup.find_all('div', class_=['job-description', 'description', 'complete-description']):
                        text = div.get_text('\n', strip=True)
                        if text and 'description' in div.get('id', '').lower():
                            complete_desc = text
                            break
                    if not complete_desc:
                        for p in soup.find_all('p', string=True):
                            text = p.get_text(strip=True)
                            if text and any(kw in text.lower() for kw in ['job description', 'complete description', 'requisition description']):
                                complete_desc = text
                                break
            except Exception as e:
                print(f"  Complete description extraction error: {str(e)}")
                try:
                    driver.switch_to.parent_frame()  # Use parent_frame in except too
                except:
                    pass

            # Add complete description if found
            if complete_desc and complete_desc.strip():
                content.append("\nCOMPLETE DESCRIPTION:")
                content.append(complete_desc.strip())

            # Capture Requisition Description and other standalone text
            description_elements = soup.find_all(['p', 'body'], string=True)
            for elem in description_elements:
                text = elem.get_text(strip=True)
                if text and len(text) > 2 and not text.isspace() and text not in seen_keys:
                    if any(kw in text for kw in ['JOB DESCRIPTION', 'KNOWLEDGE, SKILLS, AND ABILITIES']):
                        content.append(text)
                    elif 'Contract' in text:
                        content.append("Engagement Type: Contract")
                    else:
                        content.append(text)

            # Capture Work Location from div with specific class
            work_location = soup.find('div', class_='ux-mselect-item')
            if work_location and work_location.text.strip() not in seen_keys:
                content.append(f"Work Location: {work_location.text.strip()}")

            # Switch back to main content if needed
            driver.switch_to.default_content()  # Final reset to top level

            return '\n'.join(content)

        except Exception as e:
            print(f"  Extraction error: {str(e)}")
            driver.switch_to.default_content()  # Final reset in error
            return driver.page_source
    
    def wait_for_stable_element(self, driver, locator, timeout=30, stability_time=2):
        """Wait for element to be present and stable (not changing)"""
        end_time = time.time() + timeout
        last_html = ""
        
        while time.time() < end_time:
            try:
                element = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located(locator)
                )
                current_html = element.get_attribute('outerHTML')
                if current_html == last_html:
                    time.sleep(stability_time)  # Additional stability wait
                    return element
                last_html = current_html
                time.sleep(0.5)
            except:
                time.sleep(0.5)
        
        raise TimeoutError(f"Element not stable after {timeout} seconds")
    
    def cleanup_memory(self, driver):
        """Execute JavaScript to clean up memory"""
        try:
            driver.execute_script("window.gc();")  # Trigger garbage collection
        except:
            pass
    
    def extract_skills_table(self, driver, max_retries=3):
        """Robust skills table extraction with comprehensive error handling and restart after access"""
        
        def safe_get_text(element, default="N/A"):
            """Helper function to safely get text from an element"""
            try:
                text = element.text.strip()
                return text if text else default
            except:
                return default

        for attempt in range(max_retries):
            try:
                print(f"  Attempt {attempt + 1} of {max_retries} to extract skills table")
                self.cleanup_memory(driver)
                
                # Click Skills tab with multiple strategies
                try:
                    skills_button = self.wait_for_stable_element(
                        driver, 
                        (By.XPATH, "//a[contains(., 'Skills')]"),
                        timeout=20
                    )
                    driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", skills_button)
                    time.sleep(0.5)
                    driver.execute_script("arguments[0].click();", skills_button)
                    
                    # ADDED: Restart/refresh logic specifically for skills section
                    print("  Restarting skills section after access...")
                    time.sleep(5)  # Wait 5 seconds before refresh
                    driver.refresh()  # Refresh the page
                    
                    # Re-locate and click skills tab after refresh
                    skills_button = self.wait_for_stable_element(
                        driver, 
                        (By.XPATH, "//a[contains(., 'Skills')]"),
                        timeout=20
                    )
                    driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", skills_button)
                    time.sleep(0.5)
                    driver.execute_script("arguments[0].click();", skills_button)
                    
                except Exception as click_error:
                    print(f"  Skills tab click failed: {click_error}. Trying URL navigation fallback...")
                    current_url = driver.current_url
                    if "reqID=" in current_url and "#" not in current_url:
                        driver.get(current_url + "#skills")
                        # ADDED: Restart/refresh logic for URL navigation approach
                        print("  Restarting skills section after URL navigation...")
                        time.sleep(5)
                        driver.refresh()
                        driver.get(current_url + "#skills")
                    time.sleep(3)

                # Handle iframes if present
                try:
                    iframes = driver.find_elements(By.TAG_NAME, "iframe")
                    if iframes:
                        print("  Found iframe, switching context...")
                        driver.switch_to.frame(iframes[0])
                except:
                    print("  No iframe detected or error switching to iframe")

                # Wait for skills grid to load completely
                try:
                    self.wait_for_stable_element(
                        driver,
                        (By.CSS_SELECTOR, "div.x-grid3-body"),
                        timeout=25
                    )
                    time.sleep(1)  # Additional stabilization wait
                except Exception as wait_error:
                    print(f"  Waiting for skills grid failed: {wait_error}")
                    raise

                # Extract table data
                rows = []
                row_elements = driver.find_elements(By.CSS_SELECTOR, "div.x-grid3-row")
                
                if not row_elements:
                    print("  No skill rows found, checking for alternative structure...")
                    row_elements = driver.find_elements(By.CSS_SELECTOR, "table.x-grid3-row-table")
                    
                for i, row in enumerate(row_elements):
                    try:
                        # Get all cells in the row
                        cells = row.find_elements(By.CSS_SELECTOR, "td.x-grid3-col")
                        
                        # Extract skill (first column)
                        skill = safe_get_text(cells[1].find_element(By.CSS_SELECTOR, "span.x-grid3-cell-inner"))
                        
                        # Extract type (second column)
                        req_desired = safe_get_text(cells[2].find_element(By.CSS_SELECTOR, "span.x-grid3-cell-inner"))
                        
                        # Extract duration (third column)
                        amount = safe_get_text(cells[3].find_element(By.CSS_SELECTOR, "span.x-grid3-cell-inner"))
                        
                        # Extract duration type (fourth column)
                        duration_type = safe_get_text(cells[4].find_element(By.CSS_SELECTOR, "span.x-grid3-cell-inner"))
                        
                        # Format experience
                        if amount == "N/A" or duration_type == "N/A":
                            experience = "N/A"
                        else:
                            experience = f"{amount} {duration_type}".strip()
                        
                        rows.append([skill, req_desired, experience])
                        
                    except Exception as row_error:
                        print(f"  Error processing row {i + 1}: {row_error}")
                        continue

                # Format results as markdown table
                headers = ["Skill", "Type", "Experience"]
                markdown_table = [
                    "| " + " | ".join(headers) + " |",
                    "| " + " | ".join(["---"] * len(headers)) + " |"
                ]
                
                for row in rows:
                    clean_row = [cell.replace("\n", " ").strip() for cell in row]
                    markdown_table.append("| " + " | ".join(clean_row) + " |")
                
                print("  Skills table extracted successfully")
                return "\n".join(markdown_table)

            except Exception as e:
                print(f"  Attempt {attempt + 1} failed with error: {str(e)}")
                
                # Capture debugging info
                try:
                    print(f"  Current URL: {driver.current_url}")
                    print(f"  Page title: {driver.title}")
                    driver.save_screenshot(f"error_attempt_{attempt + 1}.png")
                except:
                    pass
                
                if attempt < max_retries - 1:
                    # Recovery actions
                    try:
                        driver.switch_to.default_content()
                        driver.refresh()
                        time.sleep(5)
                    except:
                        # If recovery fails, restart browser
                        try:
                            driver.quit()
                        except:
                            pass
                        driver = self.initialize_driver()
                else:
                    print("  Max retries reached, returning empty table")
                    return "| Skill | Type | Experience |\n|-------|------|------------|\n| N/A | N/A | N/A |"
        
        return "| Skill | Type | Experience |\n|-------|------|------------|\n| N/A | N/A | N/A |"
    
    def extract_questions_section(self, driver, max_retries=3):
        """
        Extract the Questions section from the Vector VMS requisition page.
        Returns a formatted string with all questions or empty string if not found.
        """
        for attempt in range(max_retries):
            try:
                print(f"  Attempt {attempt + 1} to extract Questions section...")
                
                # Switch to iframe if present (this is often needed for VMS content)
                try:
                    iframes = driver.find_elements(By.TAG_NAME, "iframe")
                    if iframes:
                        driver.switch_to.frame(iframes[0])
                        print("  Switched to iframe for content")
                except:
                    print("  No iframe detected or error switching")
                    # Continue anyway - the content might be in the main frame

                # Look for the Questions section by its ID or header text
                questions_content = ""
                
                # Method 1: Look for the specific panel ID
                try:
                    questions_panel = driver.find_element(By.ID, "ContentPH_pnlQuestions")
                    print("  Found Questions panel by ID")
                    questions_content = questions_panel.text
                except:
                    # Method 2: Look for the header text "Questions"
                    try:
                        questions_header = driver.find_element(By.XPATH, "//*[contains(text(), 'Questions')]")
                        print("  Found Questions header text")
                        # Get the parent container of the header and extract its text
                        questions_container = questions_header.find_element(By.XPATH, "./ancestor::div[contains(@class, 'x-panel')]")
                        questions_content = questions_container.text
                    except:
                        # Method 3: Look for any element containing question text
                        try:
                            question_elements = driver.find_elements(By.XPATH, "//*[contains(text(), 'Question') or contains(text(), 'question')]")
                            if question_elements:
                                print(f"  Found {len(question_elements)} question elements")
                                questions_content = "\n".join([elem.text for elem in question_elements if elem.text.strip()])
                        except Exception as e:
                            print(f"  Error finding question elements: {e}")
                
                # If we found content, parse it for actual questions
                if questions_content:
                    print(f"  Raw questions content found: {len(questions_content)} characters")
                    
                    # Parse the content to extract just the question text
                    lines = questions_content.split('\n')
                    questions = []
                    current_question = ""
                    in_question = False
                    
                    for line in lines:
                        line = line.strip()
                        if not line:
                            continue
                            
                        # Look for question indicators
                        if line.startswith('Question') or line.startswith('Q:') or (len(line) > 20 and '?' in line and not line.startswith('Description')):
                            if current_question and current_question not in questions:
                                questions.append(current_question)
                            current_question = line
                            in_question = True
                        elif in_question and line:
                            # Continue building the current question
                            current_question += " " + line
                    
                    # Add the last question if exists
                    if current_question and current_question not in questions:
                        questions.append(current_question)
                    
                    # Filter out non-question lines
                    filtered_questions = []
                    for q in questions:
                        if ('question' in q.lower() or '?' in q) and len(q) > 10:
                            # Clean up the question text
                            q = re.sub(r'^Question\s*\d+[:.\s]*', '', q, flags=re.IGNORECASE)
                            q = q.strip()
                            if q:
                                filtered_questions.append(q)
                    
                    # Format the questions output
                    if filtered_questions:
                        formatted_questions = "=== QUESTIONS ===\n"
                        for i, question in enumerate(filtered_questions, 1):
                            formatted_questions += f"Q{i}: {question}\n"
                        
                        print(f"  Successfully extracted {len(filtered_questions)} questions")
                        # Switch back to default content before returning
                        try:
                            driver.switch_to.default_content()
                        except:
                            pass
                        return formatted_questions
                
                print("  No questions found in the section")
                # Switch back to default content
                try:
                    driver.switch_to.default_content()
                except:
                    pass
                return ""

            except Exception as e:
                print(f"  Attempt {attempt + 1} failed: {str(e)}")
                # Switch back to default content on error
                try:
                    driver.switch_to.default_content()
                except:
                    pass
                
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    print("  Max retries reached for Questions extraction")
                    return ""

        return ""
    
    def process_single_requisition(self, driver, url):
        """Process a single requisition using the credential fallback logic"""
        print(f"\nüìã Processing requisition: {url}")
        
        # Try each credential set in order
        for i, credentials in enumerate(CREDENTIAL_SETS):
            print(f"\nüîë Trying credential set {i+1}/{len(CREDENTIAL_SETS)}")
            
            # Try to login with current credentials
            login_success = self.login_to_vectorvms(driver, url, credentials)
            
            if login_success:
                try:
                    # Ensure we're in the default content context first
                    driver.switch_to.default_content()
                    time.sleep(3)
                    
                    print("  üìÑ Extracting main content...")
                    # Extract content
                    content = self.extract_complete_page_content(driver)
                    
                    print("  üîß Extracting skills table...")
                    # Extract skills table WITH RETRIES
                    skills_table = ""
                    skills_attempts = 2
                    for attempt in range(skills_attempts):
                        print(f"    Skills extraction attempt {attempt + 1}/{skills_attempts}")
                        skills_table = self.extract_skills_table(driver)
                        if skills_table and "Technical Skills" not in skills_table:
                            print(f"    ‚úÖ Got non-placeholder skills table")
                            break
                        elif attempt < skills_attempts - 1:
                            print(f"    ‚è≥ Retrying skills extraction...")
                            time.sleep(2)
                            driver.refresh()
                            time.sleep(3)
                    
                    # Ensure we're back in default context
                    driver.switch_to.default_content()
                    
                    print("  ‚ùì Extracting questions section...")
                    # Extract questions section
                    questions_section = self.extract_questions_section(driver)
                    
                    # Save results
                    req_id = re.search(r'reqID=(\d+)', url).group(1)
                    output_file = os.path.join(self.output_dir, f"requisition_{req_id}_complete.txt")
                    
                    print(f"  üíæ Saving to file: {output_file}")
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(content)
                        if skills_table:
                            f.write("\n\n=== SKILLS TABLE ===\n")
                            f.write(skills_table)
                            print(f"    ‚úÖ Saved skills table with {skills_table.count('|')//3} skills")
                        # Add questions section after skills
                        if questions_section:
                            f.write("\n\n")
                            f.write(questions_section)
                    
                    print(f"‚úÖ Saved results using org_key: {credentials['org_key']}")
                    
                    # Logout after successful extraction
                    self.logout_from_vectorvms(driver)
                    
                    return True, credentials['org_key']
                    
                except Exception as e:
                    print(f"‚ùå Error extracting data: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    # Ensure we switch back to default content on error
                    try:
                        driver.switch_to.default_content()
                    except:
                        pass
                    # Try to logout even if extraction failed
                    try:
                        self.logout_from_vectorvms(driver)
                    except:
                        pass
                    continue
            else:
                print(f"‚ùå Login failed with org_key: {credentials['org_key']}")
                # Clear cookies and try next credentials
                driver.delete_all_cookies()
                driver.refresh()
                time.sleep(2)
        
        print(f"‚ùå All credential sets failed for URL: {url}")
        return False, None
    
    def open_all_requisitions_in_new_tabs(self, driver, urls):
        """Open all requisition URLs in new tabs with credential fallback logic"""
        print(f"\nOpening {len(urls)} requisitions in new tabs...")
        
        # Store the original window handle
        original_window = driver.current_window_handle
        
        # Track credential performance
        credential_stats = {cred['org_key']: {'success': 0, 'attempts': 0} for cred in CREDENTIAL_SETS}
        
        # Process each URL
        for i, url in enumerate(urls):
            try:
                # Open new tab using JavaScript
                driver.execute_script("window.open('');")
                
                # Switch to the new tab
                all_windows = driver.window_handles
                driver.switch_to.window(all_windows[-1])
                
                # Process the requisition with credential fallback logic
                success, used_org_key = self.process_single_requisition(driver, url)
                
                # Update statistics
                if success:
                    credential_stats[used_org_key]['success'] += 1
                for cred in CREDENTIAL_SETS:
                    credential_stats[cred['org_key']]['attempts'] += 1
                
                if success:
                    print(f"‚úì Successfully processed tab {i+1}/{len(urls)}: {url}")
                else:
                    print(f"‚úó Failed to process tab {i+1}/{len(urls)}: {url}")
                
                # Close the tab and switch back to the original window
                driver.close()
                driver.switch_to.window(original_window)
                
                # Brief pause between URLs
                time.sleep(2)
                
            except Exception as e:
                print(f"Error processing URL {url}: {str(e)}")
                # Try to recover by switching back to the original window
                try:
                    driver.switch_to.window(original_window)
                except:
                    pass
                continue
        
        # Print credential performance summary
        print("\n" + "="*60)
        print("CREDENTIAL PERFORMANCE SUMMARY:")
        print("="*60)
        for org_key, stats in credential_stats.items():
            success_rate = (stats['success'] / stats['attempts'] * 100) if stats['attempts'] > 0 else 0
            print(f"Org Key {org_key}: {stats['success']} successes out of {stats['attempts']} attempts ({success_rate:.1f}% success rate)")
    
    def run_manual_processing(self, new_email_ids=None):
        """Run manual processing for SPECIFIC new emails only"""
        from services.vms.gmail_reader import GmailReader
        from services.vms.llm_processor import PureLLMRequisitionProcessor, RequisitionTitleGenerator
        from services.vms.email_sender import EmailSender  # This import already exists
        from utils.vms_helpers import extract_state_from_job_id
        
        # Initialize driver
        driver = self.initialize_driver()
        
        try:
            # First, authenticate with Gmail
            print("=== Starting Gmail Authentication ===")
            print(f"Date: {datetime.now().strftime('%Y-%m-%d')}")
            
            self.clear_vms_folders()

            gmail_reader = GmailReader()
            gmail_service = gmail_reader.authenticate()
            
            print("=== Extracting TODAY'S Requisition URLs ===")
            
            # MODIFIED: If new_email_ids is provided, extract URLs from THOSE emails only
            if new_email_ids:
                print(f"üîç Extracting URLs from {len(new_email_ids)} NEW emails only...")
                requisition_urls = []
                
                for email_id in new_email_ids:
                    try:
                        # Get full email content for this specific email ID
                        msg = gmail_service.users().messages().get(
                            userId='me',
                            id=email_id,
                            format='full'
                        ).execute()
                        
                        # Extract body
                        body = ""
                        payload = msg['payload']
                        
                        if 'parts' in payload:
                            for part in payload['parts']:
                                if part['mimeType'] == 'text/plain' and 'data' in part['body']:
                                    body = base64.urlsafe_b64decode(part['body']['data']).decode('utf-8')
                                    break
                        
                        # Extract URLs from this email's body
                        if body:
                            urls = gmail_reader.extract_direct_links(body, body)
                            if urls:
                                requisition_urls.extend(urls)
                                print(f"  üìß Email {email_id[:8]}...: {len(urls)} URLs")
                        
                    except Exception as e:
                        print(f"  ‚ùå Error extracting from email {email_id}: {e}")
                
                # Remove duplicates
                requisition_urls = list(set(requisition_urls))
                
            else:
                # Original behavior: extract ALL today's URLs (for backward compatibility)
                requisition_urls = gmail_reader.extract_todays_requisition_urls()
            
            if not requisition_urls:
                print("‚ùå No requisition URLs found. Exiting.")
                print("‚úÖ No new requisitions for today. Process complete.")
                return
            
            print(f"Found {len(requisition_urls)} requisition URLs to process:")
            for url in requisition_urls:
                print(f"  - {url}")
            
            # Open all requisitions in new tabs with credential fallback logic
            self.open_all_requisitions_in_new_tabs(driver, requisition_urls)
            
            # Import regex extraction functions
            from utils.vms_helpers import extract_all_scraped_files
            
            # ===== IMMEDIATE REGEX EXTRACTION =====
            print("\n" + "="*60)
            print("IMMEDIATE REGEX EXTRACTION")
            print("="*60)

            extraction_count = extract_all_scraped_files(output_dir='vms_outputs')
            print(f"‚úÖ Raw data extracted and saved: {extraction_count} files")

            # Process the extracted data to create documents (uses extracted data)
            print("\n=== Creating Today's Documents ===")
            self.process_requisition_files()

            # LLM Enhancement Process (uses extracted data)
            print("\n" + "="*60)
            print("ENHANCING WITH LLM")
            print("="*60)

            try:
                self.process_files_with_llm() 
            except Exception as llm_error:
                print(f"LLM processing skipped or failed: {llm_error}")
                
            # ===== EMAIL SENDING SECTION =====
            print("\n" + "="*60)
            print("SENDING EMAILS")
            print("="*60)
            
            # Send emails for all processed requisitions
            email_sender = EmailSender()  # Using the VMS EmailSender that was imported above
            email_count = 0
            
            for filename in os.listdir(self.output_dir):
                if filename.startswith("requisition_") and filename.endswith("_complete.txt"):
                    # Extract requisition ID
                    match = re.search(r'requisition_(\d+)_complete\.txt', filename)
                    if not match:
                        continue
                        
                    req_id = match.group(1)
                    
                    # Read the file content to extract state and title
                    req_file = os.path.join(self.output_dir, filename)
                    with open(req_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # Extract state abbreviation from content
                    state_abbr = extract_state_from_job_id(content)
                    if not state_abbr:
                        state_abbr = 'DEFAULT'
                    
                    # Extract title from content
                    title = "Position"
                    if "Job ID:" in content:
                        lines = content.split('\n')
                        for i, line in enumerate(lines):
                            if line.startswith('Job ID:'):
                                # Look for title in subsequent lines
                                for j in range(i+1, min(i+10, len(lines))):
                                    if lines[j].strip() and not lines[j].startswith(('Location:', 'Duration:', 'Position:')):
                                        title = lines[j].strip()
                                        break
                                break
                    
                    # Send email - FIXED: Use the EmailSender method that exists
                    from services.vms.email_sender import EmailSender
                    vms_email_sender = EmailSender()
                    success = email_sender.send_requisition_email_for_id(req_id, state_abbr, title, content)
                    
                    if success:
                        print(f"‚úÖ Email sent for requisition {req_id} (State: {state_abbr})")
                        email_count += 1
                    else:
                        print(f"‚ùå Failed to send email for requisition {req_id} (State: {state_abbr})")
            
            # ===== ORIGINAL FINAL SUMMARY =====
            print("\n=== Today's Processing Complete ===")
            print(f"Processed {len(requisition_urls)} requisitions successfully!")
            print(f"Sent {email_count} emails successfully!")
            print("All requisitions have been processed, documents created, and emails sent!")
            

            print("\nüìä TRIGGERING DUAL TABLE FOR VMS FILES")
            self.trigger_dual_table_for_vms()

            
        except Exception as main_error:
            print(f"Fatal error in processing requisitions: {str(main_error)}")
            import traceback
            traceback.print_exc()
        
        finally:
            try:
                driver.quit()
            except:
                pass
            print("Processing complete")
    
    def process_requisition_files(self):
        """
        Main function to process all requisition files and update state-specific documents
        This runs BEFORE LLM processing
        """
        # Create output directory if it doesn't exist
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
            print(f"Created output directory: {self.output_dir}")
        
        if not os.path.exists(self.updated_docs_dir):
            os.makedirs(self.updated_docs_dir)
            print(f"Created updated documents directory: {self.updated_docs_dir}")
        
        from utils.vms_helpers import (
            extract_state_from_job_id,
            parse_skills_table,
            update_rtr_document,
            update_sm_document,
            clear_updated_documents
        )
        
        # First, show what templates are available
        print("\n=== AVAILABLE TEMPLATES IN DOCUMENTS FOLDER ===")
        template_files = []
        for file in os.listdir(self.documents_dir):
            if file.endswith('.docx'):
                template_files.append(file)
                print(f"  - {file}")
        
        if not template_files:
            print("  ‚ùå No template files found in Documents folder!")
        
        # Clear previous documents before processing
        clear_updated_documents()
        
        # Process each requisition file
        processed_count = 0
        for filename in os.listdir(self.output_dir):
            if filename.startswith("requisition_") and filename.endswith("_complete.txt"):
                filepath = os.path.join(self.output_dir, filename)
                
                # Extract requisition ID from filename
                match = re.search(r'requisition_(\d+)_complete\.txt', filename)
                if not match:
                    print(f"Skipping file with unexpected format: {filename}")
                    continue
                    
                req_id = match.group(1)
                
                # Read the file content
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        content = f.read()
                except Exception as e:
                    print(f"Error reading file {filename}: {e}")
                    continue
                
                # Extract state abbreviation from content
                state_abbr = extract_state_from_job_id(content)
                print(f"\n{'='*60}")
                print(f"üìã PROCESSING REQUISITION {req_id} FOR STATE: {state_abbr}")
                print(f"{'='*60}")
                
                # Split into main content and skills table
                if "=== SKILLS TABLE ===" in content:
                    parts = content.split("=== SKILLS TABLE ===")
                    main_content = parts[0].strip()
                    skills_content = parts[1].strip()
                    # Remove questions section if present
                    if "=== QUESTIONS ===" in skills_content:
                        skills_content = skills_content.split("=== QUESTIONS ===")[0].strip()
                else:
                    main_content = content.strip()
                    skills_content = ""
                    print(f"  ‚ö†Ô∏è No skills table found in file")
                
                # Extract title from main content
                title = "Position"  # Default fallback
                # First, try to find the specific "Title/Role:" pattern
                title_match = re.search(r'Title/Role:\s*(.+)$', main_content, re.MULTILINE | re.IGNORECASE)
                if title_match:
                    title = title_match.group(1).strip()
                    # Clean up the title - remove any prefix like "NC FAST Requisition Class: DEV : "
                    clean_title = re.sub(r'^.*?(?:requisition class|nc fast)[^:]*:\s*', '', title, flags=re.IGNORECASE)
                    clean_title = clean_title.strip()
                    title = clean_title
                else:
                    # Fallback: Look for patterns that might indicate a title
                    lines = main_content.split('\n')
                    for line in lines:
                        line = line.strip()
                        # Skip empty lines and section headers
                        if not line or line.startswith('==') or len(line) > 100:
                            continue
                            
                        # Common title indicators (case insensitive)
                        if any(keyword in line.lower() for keyword in 
                               ['engineer', 'developer', 'analyst', 'manager', 'specialist', 
                                'consultant', 'architect', 'administrator', 'designer']):
                            # Clean up the title - remove any prefix like "NC FAST Requisition Class: DEV : "
                            clean_title = re.sub(r'^.*?(?:requisition class|nc fast)[^:]*:\s*', '', line, flags=re.IGNORECASE)
                            clean_title = clean_title.strip()
                            title = clean_title
                            break
                    # Final fallback: return the first meaningful line
                    for line in lines:
                        if line.strip() and not line.startswith('=='):
                            clean_title = re.sub(r'^.*?(?:requisition class|nc fast)[^:]*:\s*', '', line.strip(), flags=re.IGNORECASE)
                            title = clean_title.strip()
                            break
                
                print(f"üìù Extracted title: {title}")
                
                # Extract skills from content
                print(f"üîß Extracting skills from content...")
                skills_data = []

                # FIRST: Check for regex-extracted format (SKILLS TABLE: section)
                if "SKILLS TABLE:" in content:
                    print(f"  üìä Found 'SKILLS TABLE:' section (regex-extracted format)")
                    
                    # Extract everything from "SKILLS TABLE:" to the next major section
                    start_idx = content.find("SKILLS TABLE:")
                    if start_idx != -1:
                        # Get the substring starting from SKILLS TABLE:
                        from_skills = content[start_idx:]
                        
                        # Find the next major section
                        next_sections = [
                            "Description:", "SHORT DESCRIPTION:", "COMPLETE DESCRIPTION:", 
                            "Job ID:", "Location:", "Duration:", "Positions:",
                            "\n\n\n", "\n\n"
                        ]
                        
                        end_idx = len(from_skills)
                        for section in next_sections:
                            idx = from_skills.find(section)
                            if idx != -1 and idx < end_idx:
                                end_idx = idx
                        
                        # Extract skills text
                        skills_text = from_skills[:end_idx].strip()
                        
                        # Parse using our new function
                        from utils.vms_helpers import parse_regex_extracted_skills
                        skills_data = parse_regex_extracted_skills(skills_text)
                        
                        if skills_data:
                            print(f"  ‚úÖ Successfully extracted {len(skills_data)} skills from regex format")

                # SECOND: If no skills found, try original markdown table format
                if not skills_data and "=== SKILLS TABLE ===" in content:
                    print(f"  üìä Found '=== SKILLS TABLE ===' (original scraped format)")
                    parts = content.split("=== SKILLS TABLE ===")
                    if len(parts) > 1:
                        skills_content = parts[1].split("\n\n")[0].strip()
                        skills_data = parse_skills_table(skills_content)
                        print(f"  ‚úÖ Parsed {len(skills_data)} skills from markdown table")

                # THIRD: If still no skills, try LLM format
                if not skills_data and "skills:" in content.lower():
                    print(f"  ü§ñ Found 'skills:' section (LLM format)")
                    # Try to extract skills in LLM format
                    lines = content.split('\n')
                    in_skills = False
                    skills_lines = []
                    
                    for line in lines:
                        if line.strip().lower() == 'skills:':
                            in_skills = True
                            continue
                        elif in_skills and line.strip():
                            if any(line.strip().startswith(section) for section in 
                                  ['Description:', 'Job ID:', 'Location:', 'Duration:', 'Positions:']):
                                break
                            skills_lines.append(line.strip())
                        elif in_skills and not line.strip():
                            break
                    
                    if skills_lines:
                        skills_text = '\n'.join(skills_lines)
                        from utils.vms_helpers import parse_regex_extracted_skills
                        skills_data = parse_regex_extracted_skills(skills_text)
                        print(f"  ‚úÖ Parsed {len(skills_data)} skills from LLM format")

                # FOURTH: If still no skills, create placeholder
                if not skills_data:
                    print(f"  ‚ö†Ô∏è No skills found, creating placeholder")
                    skills_data = [{
                        'skill': f"{title} Skills",
                        'type': 'Required',
                        'experience': '',
                        'years': '5'
                    }]
                    print(f"  ‚ö†Ô∏è Created placeholder skill from title")

                # DEBUG: Show final skills
                print(f"  üìã Final skills count: {len(skills_data)}")
                if skills_data:
                    print(f"  üìã Skills to be used in SM document:")
                    for i, skill in enumerate(skills_data[:5]):  # Show first 5
                        print(f"    {i+1}. {skill.get('skill', 'N/A')}")
                    if len(skills_data) > 5:
                        print(f"    ... and {len(skills_data) - 5} more")
                else:
                    print(f"  ‚ùå No skills data available!")
                    # Create at least one skill from the title
                    skills_data = [{
                        'skill': f"{title} Skills",
                        'type': 'Required',
                        'experience': '',
                        'years': '5'
                    }]
                    print(f"  ‚ö†Ô∏è Created placeholder skill from title")
                
                # Update state-specific documents
                rtr_output = os.path.join(self.updated_docs_dir, f"RTR_{state_abbr}_{req_id}.docx")
                sm_output = os.path.join(self.updated_docs_dir, f"SM_{state_abbr}_{req_id}.docx")
                
                print(f"\n--- UPDATING RTR DOCUMENT ---")
                actual_rtr_path = update_rtr_document(req_id, title, state_abbr, self.documents_dir, 
                                                      rtr_output, requisition_content=content, 
                                                      skills_data=skills_data)
                
                print(f"\n--- UPDATING SM DOCUMENT ---")
                # Pass ALL parameters including the full content
                actual_sm_path = update_sm_document(
                    skills_data, 
                    state_abbr, 
                    self.documents_dir, 
                    sm_output, 
                    requisition_content=content
                )
                
                # Verify the documents were created successfully
                if actual_rtr_path and actual_sm_path:
                    # Check if files were saved with correct state codes
                    rtr_filename = os.path.basename(actual_rtr_path)
                    sm_filename = os.path.basename(actual_sm_path)
                    
                    if f"_{state_abbr}_" in rtr_filename and f"_{state_abbr}_" in sm_filename:
                        print(f"‚úÖ SUCCESS: Documents created with correct state codes")
                        print(f"   üìÑ RTR: {rtr_filename}")
                        print(f"   üìÑ SM: {sm_filename}")
                    else:
                        print(f"‚ö†Ô∏è  WARNING: Documents may have incorrect naming:")
                        print(f"   üìÑ RTR: {rtr_filename}")
                        print(f"   üìÑ SM: {sm_filename}")
                    
                    # Verify files actually exist
                    rtr_exists = os.path.exists(actual_rtr_path)
                    sm_exists = os.path.exists(actual_sm_path)
                    
                    if rtr_exists and sm_exists:
                        print(f"‚úÖ Files verified on disk")
                        processed_count += 1
                    else:
                        print(f"‚ùå ERROR: Files not found on disk:")
                        print(f"   RTR exists: {rtr_exists}")
                        print(f"   SM exists: {sm_exists}")
                else:
                    print(f"‚ùå FAILED: Could not create documents for requisition {req_id}")
                    if not actual_rtr_path:
                        print(f"   RTR document creation failed")
                    if not actual_sm_path:
                        print(f"   SM document creation failed")
                
                print(f"\n{'='*60}")
        
        print(f"\n=== PROCESSING COMPLETE ===")
        print(f"‚úÖ Successfully processed {processed_count} requisitions")
        
        # Show all created documents
        print(f"\n=== CREATED DOCUMENTS IN {self.updated_docs_dir} ===")
        sm_files = [f for f in os.listdir(self.updated_docs_dir) if f.startswith('SM_') and f.endswith('.docx')]
        rtr_files = [f for f in os.listdir(self.updated_docs_dir) if f.startswith('RTR_') and f.endswith('.docx')]
        
        print(f"üìÑ SM Documents: {len(sm_files)}")
        for sm_file in sm_files:
            state_from_filename = re.search(r'SM_([A-Z]{2})_', sm_file)
            state_code = state_from_filename.group(1) if state_from_filename else "UNKNOWN"
            print(f"  - {sm_file} (State: {state_code})")
        
        print(f"üìÑ RTR Documents: {len(rtr_files)}")
        for rtr_file in rtr_files:
            state_from_filename = re.search(r'RTR_([A-Z]{2})_', rtr_file)
            state_code = state_from_filename.group(1) if state_from_filename else "UNKNOWN"
            print(f"  - {rtr_file} (State: {state_code})")
        
        return processed_count
    
    def process_files_with_llm(self):
        """Process extracted data with exact formatting"""
        print("\n=== PROCESSING EXTRACTED DATA WITH EXACT FORMATTING ===")
        
        from services.vms.llm_processor import PureLLMRequisitionProcessor, RequisitionTitleGenerator
        import re
        processor = PureLLMRequisitionProcessor()
        title_generator = RequisitionTitleGenerator()
        
        requisition_files = [os.path.join(self.output_dir, f) for f in os.listdir(self.output_dir) 
                            if f.endswith('.txt') and f.startswith('requisition_')]
        
        for i, file_path in enumerate(requisition_files):
            filename = os.path.basename(file_path)
            print(f"\nüìÑ Processing {i+1}/{len(requisition_files)}: {filename}")
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    file_content = f.read()
                
                # üü¢ **NEW: Extract requisition ID BEFORE processing**
                req_match = re.search(r'requisition_(\d+)_complete\.txt', filename)
                current_req_id = req_match.group(1) if req_match else "unknown"
                print(f"  üÜî Current requisition ID from filename: {current_req_id}")
                
                # Check if already processed (has "Job ID:" header)
                if "Job ID:" in file_content and "title:" in file_content:
                    print("  ‚úÖ Already formatted, skipping")
                    continue
                elif "Requisition Number:" in file_content:
                    print("  ‚úÖ Processing extracted data")
                    
                    # STEP 1: GENERATE TITLE
                    print("  üéØ Generating title...")
                    title = title_generator.generate_title(file_content)
                    
                    if title:
                        print(f"  ‚úÖ Final Title: {title}")
                    else:
                        print("  ‚ùå Title generation failed")
                        title = "Position"
                    
                    # STEP 2: FORMAT CONTENT WITH ONLY THE FINAL TITLE
                    print("  üìù Formatting content with title in correct place...")
                    formatted_content = processor.process_extracted_data(file_content, filename, title)
                    
                    if formatted_content:
                        # üü¢ **CRITICAL FIX: POST-PROCESSING CORRECTION FOR CONTAMINATION**
                        print("  üîç Checking for cross-contamination...")
                        
                        # Fix 1: Replace wrong GA Job ID with correct VA Job ID
                        if current_req_id == "789761" and "GA-788565" in formatted_content:
                            print(f"  ‚ö†Ô∏è  DETECTED WRONG JOB ID: GA-788565 in requisition {current_req_id}")
                            print(f"  üîß Fixing Job ID to: VA-{current_req_id}")
                            
                            formatted_content = formatted_content.replace(
                                "Job ID: GA-788565",
                                f"Job ID: VA-{current_req_id}"
                            )
                            
                            # Also fix any other occurrences
                            formatted_content = formatted_content.replace(
                                "GA-788565",
                                f"VA-{current_req_id}"
                            )
                        
                        # Fix 2: If Job ID starts with wrong state, correct it
                        from utils.vms_helpers import extract_state_from_job_id
                        actual_state = extract_state_from_job_id(file_content)
                        
                        if actual_state and actual_state != 'DEFAULT':
                            # Find the Job ID line and correct it
                            lines = formatted_content.split('\n')
                            for i, line in enumerate(lines):
                                if line.startswith('Job ID:'):
                                    # Extract the state from the line
                                    job_id_match = re.search(r'Job ID:\s*([A-Z]{2})-(\d+)', line)
                                    if job_id_match:
                                        found_state = job_id_match.group(1)
                                        found_req = job_id_match.group(2)
                                        
                                        if found_state != actual_state and found_req != current_req_id:
                                            print(f"  üîß Correcting wrong state {found_state} to {actual_state}")
                                            lines[i] = f"Job ID: {actual_state}-{current_req_id}"
                                            break
                            
                            formatted_content = '\n'.join(lines)
                        
                        with open(file_path, 'w', encoding='utf-8') as f:
                            f.write(formatted_content)
                        print("  ‚úÖ Exact formatting complete with contamination fixes")
                    else:
                        print("  ‚ö†Ô∏è Formatting failed, using fallback")
                        # Fallback with clean title only
                        fallback_content = f"""Job ID: [Need to extract]

    title: {title}

    Location: [Need to extract]
    Duration: [Need to extract]
    Positions: [Need to extract]

    skills:
    [Need to extract skills table]

    Description:
    [Need to extract description]"""
                        with open(file_path, 'w', encoding='utf-8') as f:
                            f.write(fallback_content)
                else:
                    print("  ‚ö†Ô∏è No extracted data found, skipping")
                    continue
                
                if i < len(requisition_files) - 1:
                    time.sleep(3)
                    
            except Exception as e:
                print(f"  ‚ùå Error: {str(e)}")

    def clear_vms_folders(self):
        """Clear VMS folders before processing"""
        print("\nüóëÔ∏è  CLEARING VMS FOLDERS")
        
        # Clear vms_documents folder
        documents_dir = "vms_documents"
        if os.path.exists(documents_dir):
            files_cleared = 0
            for file in os.listdir(documents_dir):
                file_path = os.path.join(documents_dir, file)
                try:
                    if os.path.isfile(file_path):
                        os.remove(file_path)
                        files_cleared += 1
                        print(f"  ‚úÖ Cleared: {file}")
                except Exception as e:
                    print(f"  ‚ö†Ô∏è  Could not clear {file}: {e}")
            print(f"  üìÇ Cleared {files_cleared} files from {documents_dir}")
        else:
            os.makedirs(documents_dir)
            print(f"  üìÇ Created directory: {documents_dir}")
        
        # Clear vms_outputs folder
        output_dir = "vms_outputs"
        if os.path.exists(output_dir):
            files_cleared = 0
            for file in os.listdir(output_dir):
                file_path = os.path.join(output_dir, file)
                try:
                    if os.path.isfile(file_path):
                        os.remove(file_path)
                        files_cleared += 1
                except:
                    pass
            print(f"  üìÇ Cleared {files_cleared} files from {output_dir}")
        else:
            os.makedirs(output_dir)
            print(f"  üìÇ Created directory: {output_dir}")
    
    def trigger_dual_table_for_vms(self):
        """Trigger dual table processing after VMS processing"""
        try:
            print("\nüìä TRIGGERING DUAL TABLE FOR VMS FILES")
            
            # Check if there are output files
            output_dir = "vms_outputs"
            if os.path.exists(output_dir):
                txt_files = [f for f in os.listdir(output_dir) if f.endswith('.txt')]
                
                if txt_files:
                    print(f"  ‚úÖ Found {len(txt_files)} VMS files, running dual table...")
                    
                    # Import and run dual table
                    from services.dual_table.dual_table_service import run_dual_table_processing
                    run_dual_table_processing()
                    
                    print("  ‚úÖ Dual table completed for VMS files")
                else:
                    print("  ‚è≠Ô∏è  No VMS output files found")
            else:
                print("  ‚è≠Ô∏è  No VMS output directory")
                
        except Exception as e:
            print(f"  ‚ùå Error triggering dual table: {e}")